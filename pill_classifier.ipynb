{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c20af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms.v2 import Resize, RandomRotation, Compose, RandomVerticalFlip, RandomHorizontalFlip\n",
    "from torchvision.transforms import Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "import torchvision.models as models\n",
    "from matplotlib import pyplot as plt\n",
    "import data_utils as du\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb51d94",
   "metadata": {},
   "source": [
    "Загружаем изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'ogyeiv2'\n",
    "train_dataset = ImageFolder(dataset_path + '/train')\n",
    "val_dataset = ImageFolder(dataset_path + '/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_dataset.classes) == len(val_dataset.classes)\n",
    "classes = train_dataset.classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "for dataset in [train_dataset, val_dataset]:\n",
    "    print(f\"{len(dataset)} images of classes: {dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9de7e",
   "metadata": {},
   "source": [
    "Посмотрим примеры изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 10))\n",
    "for index in range(1, 3):\n",
    "    image, label = train_dataset[index]\n",
    "    print(classes[label])\n",
    "    plt.subplot(1, 10, index)\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44492179",
   "metadata": {},
   "source": [
    "Видим, что изображения имеют высокое разрешение, порядка 8Мп.\n",
    "\n",
    "Большая часть изображения это однородный фон, который не содержит никаких полезных фич. \\\n",
    "Полезных метаданных (например, centercrop, в который гарантированно поместится таблетка) по этому датасету я не нашёл, поэтому начал искать примеры статей на тему распознавания таблеток.\n",
    "\n",
    "Нашёл вот эту:\n",
    "https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/ipr2.13273\n",
    "\n",
    "Там датасет проходил препроцессинг с помощью YOLO: вырезали ббокс с таблеткой и сохраняли только его. Поступим так же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf365a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3bd821",
   "metadata": {},
   "source": [
    "Создадим датасет и загрузчик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94670b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    Resize((224, 224)),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    RandomRotation([-5, 5], fill=255.),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    Resize((224, 224)),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93175b3",
   "metadata": {},
   "source": [
    "Используем в качестве классификатора модифицированную модель EfficientNet.\n",
    "\n",
    "Заменим полносвязный слой, т. к. нам хватит 84 классов и дообучим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Посмотрим на summary модели, чтобы найти какой слой надо заменить\n",
    "summary(model, input_size=(3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc297e77",
   "metadata": {},
   "source": [
    "Замораживаем слои, подменяем последний слой, размораживаем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[1] = nn.Linear(\n",
    "    in_features=1280,\n",
    "    out_features=num_classes)\n",
    "\n",
    "for param in model.classifier[1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "summary(model, input_size=(3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf6b9e",
   "metadata": {},
   "source": [
    "Отправляем модель на GPU для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16beb69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model_yolo = YOLO(\"yolo12n.pt\")\n",
    "model_yolo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataset = du.OgyeivDataset(\n",
    "    train_dataset,\n",
    "    train_transforms,\n",
    "    model_yolo,\n",
    "    device)\n",
    "\n",
    "val_dataset = du.OgyeivDataset(\n",
    "    val_dataset,\n",
    "    val_transforms,\n",
    "    model_yolo,\n",
    "    device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f08d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    avg_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        avg_loss = running_loss / (i + 1)\n",
    "        print(f'Эпоха: {epoch_index}, батч {i}/{len(train_loader)}, ошибка {avg_loss}')\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "best_vloss = 1e5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Эпоха {epoch}')\n",
    "\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            running_vloss += criterion(voutputs, vlabels)\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'pill_classifier_{epoch}.pt'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(\n",
    "        f'Конец эпохи. Ошибка обучения: {avg_loss}, ошибка валидации: {avg_vloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9656202",
   "metadata": {},
   "source": [
    "Возвращаем модель на CPU, строим отчёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "model.eval()\n",
    "labels_predicted = []\n",
    "labels_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cpu'), labels.to('cpu')\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        labels_predicted.extend(predicted.numpy())\n",
    "        labels_true.extend(labels.numpy())\n",
    "\n",
    "print(classification_report(labels_true, labels_predicted, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sprint_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
