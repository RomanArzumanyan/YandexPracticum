{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c20af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms.v2 import Resize, RandomRotation, Compose\n",
    "from torchvision.transforms import Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "import torchvision.models as models\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb51d94",
   "metadata": {},
   "source": [
    "Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'ogyeiv2'\n",
    "train_dataset = ImageFolder(dataset_path + '/train')\n",
    "val_dataset = ImageFolder(dataset_path + '/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_dataset.classes) == len(val_dataset.classes)\n",
    "classes = train_dataset.classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "for dataset in [train_dataset, val_dataset]:\n",
    "    print(f\"{len(dataset)} images of classes: {dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9de7e",
   "metadata": {},
   "source": [
    "Посмотрим примеры изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 10))\n",
    "for index in range(1, 3):\n",
    "    image, label = train_dataset[index]\n",
    "    print(classes[label])\n",
    "    plt.subplot(1, 10, index)\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44492179",
   "metadata": {},
   "source": [
    "Видим, что изображения имеют высокое разрешение, порядка 8Мп.\n",
    "\n",
    "Большая часть изображения это днородный фон, который не содержит никаких полезных фич. \\\n",
    "Полезных метаданных (например, centercrop, в который гарантированно поместится таблетка) по этому датасету я не нашёл, поэтому начал искать примеры статей на тему распознавания таблеток.\n",
    "\n",
    "Нашёл вот эту:\n",
    "https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/ipr2.13273\n",
    "\n",
    "Там датасет проходил препроцессинг с помощью YOLO: вырезали ббокс с таблеткой и сохраняли только его.\n",
    "\n",
    "Поступим так же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf365a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb901a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PreprocDataset(Dataset):\n",
    "#     def __init__(self, dataset, model):\n",
    "#         super(PreprocDataset, self).__init__()\n",
    "#         self.dataset = dataset\n",
    "#         self.model = model\n",
    "#         self.processed = []\n",
    "\n",
    "#         for x, y in tqdm(self.dataset):\n",
    "#             results = self.model(x)\n",
    "#             for r in results:\n",
    "#                 boxes = r.boxes\n",
    "#                 for box in boxes:\n",
    "#                     bbox = map(int, box.xyxy.cpu().numpy())\n",
    "#                     print(f\"bbox: {bbox}\")\n",
    "#                     x = x.crop(bbox)\n",
    "\n",
    "#                     self.processed.append(x, y)\n",
    "#                     continue\n",
    "#                 continue\n",
    "\n",
    "#         self.dataset = self.processed\n",
    "#         self.processed = None\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x, y = self.dataset[idx]\n",
    "#         return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# model_yolo = YOLO(\"yolov8m-seg.pt\")\n",
    "# model_yolo.to(device)\n",
    "\n",
    "# preproc_val = PreprocDataset(val_dataset, model_yolo)\n",
    "# preproc_train = PreprocDataset(train_dataset, model_yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaedc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Посмотрим на детектированные таблетки\n",
    "# fig = plt.figure(figsize=(30, 10))\n",
    "# for i in range(1, 4):\n",
    "#     index = np.random.randint(1, 42)\n",
    "#     image, label = preproc_val[index]\n",
    "#     print(classes[label])\n",
    "#     plt.subplot(1, 10, i)\n",
    "#     plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4ff43",
   "metadata": {},
   "source": [
    "Так гораздо лучше.\n",
    "\n",
    "Сохраним обработанный датасет на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# output_root_dir = \"processed_ogyeiv2/train\"\n",
    "# output_root_dir = \"processed_ogyeiv2/test\"\n",
    "# os.makedirs(output_root_dir, exist_ok=True)\n",
    "\n",
    "# for i, (image, label) in enumerate(preproc_val):\n",
    "#     class_name = classes[label]\n",
    "#     class_dir = os.path.join(output_root_dir, class_name)\n",
    "#     os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "#     # Save the image\n",
    "#     image_filename = os.path.join(class_dir, f\"image_{i:05d}.png\")\n",
    "#     image.save(image_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3bd821",
   "metadata": {},
   "source": [
    "Создадим датасет и загрузчик.\n",
    "\n",
    "Вертикальный и горизонтальный поворот не используем, может \"поплыть\" маркировка на некоторых таблетках (aspirin, atorvastatin и пр.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94670b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    RandomRotation([-5, 5], fill=255.),\n",
    "    Resize((224, 224)),\n",
    "    Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    Resize((224, 224)),\n",
    "    Normalize((0.5), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38feddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OgyeivDataset(Dataset):\n",
    "    def __init__(self, dataset, transforms):\n",
    "        super(OgyeivDataset, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "        self.to_tensor = ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x копируем в vRAM, а y -нет. Почему так?\n",
    "        # GPU быстрее выполнит преобразования над изображениями, поэтому их выложим в vRAM сразу.\n",
    "        # Однако, y - это просто переменная типа int, лучше её скопировать в vRAM батчем.\n",
    "        x, y = self.dataset[idx]\n",
    "        x = self.to_tensor(x).to(device)\n",
    "        return self.transforms(x), y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93175b3",
   "metadata": {},
   "source": [
    "Используем в качестве классификатора модифицированную модель EfficientNet.\n",
    "\n",
    "\n",
    "Почему именно её ? Мы хотим распознавать таблетки с точностью около 75%. Судя по изложенному в теории, это достаточно высокая точность, а значит нужна модель с большей точностью, пускай и не такая быстрая. \n",
    "\n",
    "Кроме того, цена ошибки распознавания достаточно высока.\n",
    "\n",
    "Заменим полносвязный слой, т. к. нам хватит 84 классов и дообучим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Посмотрим на summary модели, чтобы найти какой слой надо заменить\n",
    "summary(model, input_size=(3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc297e77",
   "metadata": {},
   "source": [
    "Замораживаем слои, подменяем последний слой, размораживаем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier[1] = nn.Linear(\n",
    "    in_features=1280,\n",
    "    out_features=num_classes)\n",
    "\n",
    "for param in model.classifier[1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "summary(model, input_size=(3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf6b9e",
   "metadata": {},
   "source": [
    "Отправляем модель на GPU для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16beb69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = OgyeivDataset(train_dataset, train_transforms)\n",
    "val_dataset = OgyeivDataset(val_dataset, val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f08d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    avg_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        avg_loss = running_loss / (i + 1)\n",
    "        print(f'Эпоха: {epoch_index}, батч {i}/{len(train_loader)}, ошибка {avg_loss}')\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "best_vloss = 1e5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Эпоха {epoch}')\n",
    "\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            running_vloss += criterion(voutputs, vlabels)\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'pill_classifier_{epoch}.pt'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(\n",
    "        f'Конец эпохи. Ошибка обучения: {avg_loss}, ошибка валидации: {avg_vloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9656202",
   "metadata": {},
   "source": [
    "Возвращаем модель на CPU, строим отчёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "model.eval()\n",
    "labels_predicted = []\n",
    "labels_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cpu'), labels.to('cpu')\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        labels_predicted.extend(predicted.numpy())\n",
    "        labels_true.extend(labels.numpy())\n",
    "\n",
    "print(classification_report(labels_true, labels_predicted, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sprint_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
