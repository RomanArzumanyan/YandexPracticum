{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8843c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data_utils, data_set, lstm_model, transformer\n",
    "TOKENIZER = data_set.TOKENIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc169a34",
   "metadata": {},
   "source": [
    "Prepare datasets and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7165777",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = data_utils.clean_up(data_utils.load_dataset(\n",
    "    \"data/raw_dataset.txt\", cap=100000))\n",
    "\n",
    "splits = data_utils.split_dataset(clean)\n",
    "\n",
    "data_sets = []\n",
    "data_loaders = []\n",
    "for split_name in splits:\n",
    "    shuffle = 'test' == split_name\n",
    "    dset, dloader = data_set.prepare_data(\n",
    "        splits[split_name], shuffle)\n",
    "    data_sets.append(dset)\n",
    "    data_loaders.append(dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb550267",
   "metadata": {},
   "source": [
    "Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = lstm_model.Lstm(TOKENIZER)\n",
    "lstm_model.train(lstm, n_epochs=3, l_rate=0.002, tokenizer=TOKENIZER,\n",
    "                 train_loader=data_loaders[0], val_loader=data_loaders[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca439fac",
   "metadata": {},
   "source": [
    "LSTM inference and autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.inference(\n",
    "    lstm, loader=data_loaders[2], tokenizer=TOKENIZER)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter sentence, \\\"quit\\\" to exit: \")\n",
    "    if user_input == \"quit\":\n",
    "        break\n",
    "\n",
    "    # Predict last 1/4 of sentence\n",
    "    num_words = max(1, len(user_input.split()) // 3)\n",
    "\n",
    "    # Autoregression is done via concatenation of user input and\n",
    "    # model output\n",
    "    for i in range(0, num_words):\n",
    "        clean = data_utils.clean_up([user_input])\n",
    "        _, dloader = data_set.prepare_data(clean)\n",
    "        user_input = user_input + \" \" + \\\n",
    "            lstm_model.inference(lstm, loader=dloader,\n",
    "                                 tokenizer=TOKENIZER, interactive=True)[-1]\n",
    "    print(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44786259",
   "metadata": {},
   "source": [
    "DistilGPT2 inference and autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cc692",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = transformer.DistilGPT2()\n",
    "gpt2.inference(splits[\"test\"])\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter sentence, \\\"quit\\\" to exit: \")\n",
    "    if user_input == \"quit\":\n",
    "        break\n",
    "\n",
    "    # Predict last 1/4 of sentence\n",
    "    num_words = max(1, len(user_input.split()) // 3)\n",
    "\n",
    "    # Autoregression is done via concatenation of user input and\n",
    "    # model output\n",
    "    for i in range(0, num_words):\n",
    "        clean = data_utils.clean_up([user_input])\n",
    "        user_input = user_input + \" \" + gpt2.autocomplete(user_input)\n",
    "    print(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sprint_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
