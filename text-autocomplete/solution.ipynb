{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f180e0c9",
   "metadata": {},
   "source": [
    "Импортируем модули и глобальные переменные на уровне модулей.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e871b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlabs/Documents/Yandex_Practicum_ML_CV/venv_sprint_2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src import data_utils, data_set, lstm_model, transformer\n",
    "\n",
    "TOKENIZER = data_set.TOKENIZER\n",
    "MIN_LEN = data_set.MIN_LEN\n",
    "ROUGE = lstm_model.ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc169a34",
   "metadata": {},
   "source": [
    "Готовим данные:\n",
    "- Загружаем датасет.\n",
    "- Чистим его с помощью регулярных выражений.\n",
    "- Разбиваем на сеты для обучения и валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56dd5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://code.s3.yandex.net/deep-learning/tweets.txt\"\n",
    "filename = \"data/raw_dataset.txt\"\n",
    "data_utils.download_from_url(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7165777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:00<00:00, 212228.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set len:       80000\n",
      "validataion set len: 10000\n",
      "test set len:        10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:06<00:00, 12952.41it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 9025.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Аргумент cap ограничивает число строк, которые будут загружены.\n",
    "# Значения до 100К удобны для проверки. Тетрадка отработает за несколько минут.\n",
    "clean = data_utils.clean_up(data_utils.load_dataset(\n",
    "    \"data/raw_dataset.txt\", cap=50000))\n",
    "\n",
    "splits = data_utils.split_dataset(clean)\n",
    "\n",
    "data_sets = []\n",
    "data_loaders = []\n",
    "for split in [splits['train'], splits['val']]:\n",
    "    dset = data_set.TwitterDataset(split)\n",
    "    data_sets.append(dset)\n",
    "    data_loaders.append(dset.get_loader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb550267",
   "metadata": {},
   "source": [
    "Обучаем LSTM модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d8425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:08<00:00, 37.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 6.857 | Val Loss: 6.104 | Val Accuracy: 15.89%\n",
      "ROUGE metrics\n",
      "rouge1: 0.2515\n",
      "rouge2: 0.0177\n",
      "rougeL: 0.1486\n",
      "rougeLsum: 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:06<00:00, 44.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 5.321 | Val Loss: 5.807 | Val Accuracy: 19.14%\n",
      "ROUGE metrics\n",
      "rouge1: 0.2938\n",
      "rouge2: 0.0216\n",
      "rougeL: 0.1603\n",
      "rougeLsum: 0.1607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305/305 [00:07<00:00, 42.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 4.459 | Val Loss: 5.913 | Val Accuracy: 20.03%\n",
      "ROUGE metrics\n",
      "rouge1: 0.2959\n",
      "rouge2: 0.0221\n",
      "rougeL: 0.1637\n",
      "rougeLsum: 0.1639\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_model.Lstm(TOKENIZER)\n",
    "lstm.train_model(n_epochs=3, l_rate=0.002, tokenizer=TOKENIZER,\n",
    "                 train_loader=data_loaders[0], val_loader=data_loaders[1])\n",
    "\n",
    "# Сохраняем модель для инференса\n",
    "lstm.save_state_dict(\"models/lstm_state_dict.pth\")\n",
    "\n",
    "# И целиком\n",
    "lstm.save(\"models/lstm_entire.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3184f",
   "metadata": {},
   "source": [
    "В ходе обучения предсказываем 3 слова для каждого предложения.\n",
    "\n",
    "Почему так ? В задании сказано \"предсказать оставшуюся 1/4 часть предложения\". \\\n",
    "Т. к. предложения разной длины, то элементы батча будут обработаны разное число раз. \\\n",
    "Это ограничит возможности использования батчей, вот возможные варианты:\n",
    "- Отказаться от батчей вовсе.\n",
    "- Отсортировать предложения по длине и использовать маленький батч (чтобы длины в батче совпадали)\n",
    "- Зафиксирваоть число слов (1/4 минимальной длины предложения или максмальной и т. п.)\n",
    "\n",
    "\n",
    "Получается логика обработки, которая не имеет никакого отношения к обучению нейросетям. Как будто, эта работа лишняя. \\\n",
    "Если вы настаиваете, я решу задачу одним из описанных способов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e097e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca439fac",
   "metadata": {},
   "source": [
    "Инференс с авторегрессией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5d4edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем датасет для инференса, т. к. мы обучаем модель предсказывать только\n",
    "# 1 слово, а инференс хотим делать для нескольких.\n",
    "lstm_data = []\n",
    "true_preds = []\n",
    "full_texts = []\n",
    "\n",
    "for i in range(0, len(splits['test'])):\n",
    "    words = splits['test'][i].split()\n",
    "    if len(words) < MIN_LEN + NUM_WORDS:\n",
    "        continue\n",
    "    ctx_len = len(words) - NUM_WORDS\n",
    "    context = ' '.join(words[:ctx_len])\n",
    "    target = ' '.join(words[ctx_len:])\n",
    "    lstm_data.append(context)\n",
    "    true_preds.append(target)\n",
    "    full_texts.append(context + \" \" + target)\n",
    "\n",
    "# Данные для инференса трансформера будут точно такие же, делаем копию.\n",
    "gpt2_data = lstm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61dea6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8181/8181 [00:00<00:00, 12663.03it/s]\n",
      "100%|██████████| 8181/8181 [00:00<00:00, 14678.58it/s]\n",
      "100%|██████████| 8181/8181 [00:00<00:00, 14839.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE metrics\n",
      "rouge1: 0.0335\n",
      "rouge2: 0.0020\n",
      "rougeL: 0.0333\n",
      "rougeLsum: 0.0333\n"
     ]
    }
   ],
   "source": [
    "# Здесь храним только предсказанные слова.\n",
    "pred_data = [\"\"] * len(lstm_data)\n",
    "\n",
    "# Проходимся по всему датасету и генерируем массив предсказанных слов.\n",
    "# Далее, прибавляем предсказанное слово ко входам.\n",
    "for i in range(0, NUM_WORDS):\n",
    "    dataset = data_set.TwitterDataset(lstm_data, shuffle=False, num_targets=0)\n",
    "    preds = lstm.inference(loader=dataset.get_loader(), tokenizer=TOKENIZER)\n",
    "    lstm_data = [x + ' ' + y for x, y in zip(lstm_data, preds)]\n",
    "    pred_data = [x + ' ' + y for x, y in zip(pred_data, preds)]\n",
    "\n",
    "rouge_score = ROUGE.compute(predictions=pred_data, references=true_preds)\n",
    "print('ROUGE metrics')\n",
    "for k, v in rouge_score.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44786259",
   "metadata": {},
   "source": [
    "Аналогичная процедура для трансформера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d5cc692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "8181it [00:26, 306.10it/s]                    \n",
      "8181it [00:28, 290.74it/s]                    \n",
      "8181it [00:33, 243.94it/s]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE metrics\n",
      "rouge1: 0.0630\n",
      "rouge2: 0.0088\n",
      "rougeL: 0.0627\n",
      "rougeLsum: 0.0627\n"
     ]
    }
   ],
   "source": [
    "pred_data = [\"\"] * len(lstm_data)\n",
    "\n",
    "gpt2 = transformer.DistilGPT2()\n",
    "for i in range(0, NUM_WORDS):\n",
    "    preds = gpt2.inference(gpt2_data)\n",
    "    gpt2_data = [x + ' ' + y for x, y in zip(gpt2_data, preds)]\n",
    "    pred_data = [x + ' ' + y for x, y in zip(pred_data, preds)]\n",
    "\n",
    "rouge_score = ROUGE.compute(predictions=pred_data, references=true_preds)\n",
    "print('ROUGE metrics')\n",
    "for k, v in rouge_score.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee31708",
   "metadata": {},
   "source": [
    "Посмотрим на некоторые результаты работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7325b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some LSTM predictions:\n",
      "nicksantino warped but you guys wont be on the florida dates ##s ##nl ##r\n",
      "miafreedman i m loving harem pants at the moment seriously but not the ones with a crutch to twitter it yet\n",
      "watched some more planet earth with my dad the ice worlds episode has super sad moments poor polar bears ##y ##y work\n",
      "\n",
      "Some GPT2 predictions:\n",
      "nicksantino warped but you guys wont be on the florida dates and are so\n",
      "miafreedman i m loving harem pants at the moment seriously but not the ones with a crutch to grab and grab\n",
      "watched some more planet earth with my dad the ice worlds episode has super sad moments poor polar bears in a forest\n",
      "\n",
      "Actual sentences:\n",
      "nicksantino warped but you guys wont be on the florida dates im so sad\n",
      "miafreedman i m loving harem pants at the moment seriously but not the ones with a crutch to the knee ewwww\n",
      "watched some more planet earth with my dad the ice worlds episode has super sad moments poor polar bears and baby penguins\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSome LSTM predictions:\")\n",
    "for i in range(0, 3):\n",
    "    print(lstm_data[i])\n",
    "\n",
    "print(\"\\nSome GPT2 predictions:\")\n",
    "for i in range(0, 3):\n",
    "    print(gpt2_data[i])\n",
    "\n",
    "print(\"\\nActual sentences:\")\n",
    "for i in range(0, 3):\n",
    "    print(full_texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c0e16",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- Использование трансформера избыточно для этой задачи.\n",
    "- LSTM с небольшим скрытым состоянием (128) справляется с задачей предсказания следующего слова лучше.\n",
    "- Эксперименты по увеличению размера скрытого состояния LSTM (до 384) показали, что на коротких текстах это бессмысленно. Accuracy достигает значения, близкого к максимальному уже на 1й эпохе, а потом прекращает рост.\n",
    "- Меньший размер скрытого состояния (128) даёт схожее значение accuracy уже на 3й эпохе обучения.\n",
    "- Траснформер выдаёт более \"осмысленные\", но менее точные предсказания при авторегрессии."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sprint_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
